{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "The basics of market basket analysis\n",
    "Market basket analysis uses lists of transactions to identify useful associations between items. Such associations can be written in the form of a rule that has an antecedent and a consequent. Let's assume a small grocery store has asked you to look at their transaction data. After some analysis, you find the rule given below.\n",
    "\n",
    "{cereal}--- {milk}\n",
    "\n",
    "\n",
    "{cereal} is the antecedent, {milk} is the consequent, and both are items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In [1]:\n",
    "groceries.head()\n",
    "Out[1]:\n",
    "\n",
    "                 Transaction\n",
    "0         milk,bread,biscuit\n",
    "1  bread,milk,biscuit,cereal\n",
    "2                  bread,tea\n",
    "3             jam,bread,milk\n",
    "4                tea,biscuit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas under the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Load transactions from pandas\n",
    "groceries = pd.read_csv(groceries_path)\n",
    "\n",
    "# Split transaction strings into lists\n",
    "transactions = groceries['Transaction'].apply(lambda t: t.split(','))\n",
    "\n",
    "# Convert DataFrame column into list of strings\n",
    "transactions = list(transactions)\n",
    "\n",
    "# Print the list of transactions\n",
    "print(transactions)\n",
    "'''\n",
    "[['milk', 'bread', 'biscuit'], ['bread', 'milk', 'biscuit', 'cereal'], ['bread', 'tea'], ['jam', 'bread', 'milk'], ['tea', 'biscuit'], ['bread', 'tea'], ['tea', 'cereal'], ['bread', 'tea', 'biscuit'], ['jam', 'bread', 'tea'], ['bread', 'milk'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'sugar'], ['bread', 'coffee', 'orange'], ['bread', 'sugar', 'biscuit'], ['coffee', 'sugar', 'cereal'], ['bread', 'sugar', 'biscuit'], ['bread', 'coffee', 'sugar'], ['bread', 'coffee', 'sugar'], ['tea', 'milk', 'coffee', 'cereal']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import permutations from the itertools module\n",
    "from itertools import permutations\n",
    "\n",
    "# Define the set of groceries\n",
    "flattened = [i for t in transactions for i in t]\n",
    "groceries = list(set(flattened))\n",
    "\n",
    "# Generate all possible rules\n",
    "rules = list(permutations(groceries, 2))\n",
    "\n",
    "# Print the set of rules\n",
    "print(rules)\n",
    "\n",
    "# Print the number of rules\n",
    "print(len(rules))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "[('cereal', 'biscuit'), ('cereal', 'milk'), ('cereal', 'orange'), ('cereal', 'coffee'), ('cereal', 'bread'), ('cereal', 'jam'), ('cereal', 'sugar'), ('cereal', 'tea'), ('biscuit', 'cereal'), ('biscuit', 'milk'), ('biscuit', 'orange'), ('biscuit', 'coffee'), ('biscuit', 'bread'), ('biscuit', 'jam'), ('biscuit', 'sugar'), ('biscuit', 'tea'), ('milk', 'cereal'), ('milk', 'biscuit'), ('milk', 'orange'), ('milk', 'coffee'), ('milk', 'bread'), ('milk', 'jam'), ('milk', 'sugar'), ('milk', 'tea'), ('orange', 'cereal'), ('orange', 'biscuit'), ('orange', 'milk'), ('orange', 'coffee'), ('orange', 'bread'), ('orange', 'jam'), ('orange', 'sugar'), ('orange', 'tea'), ('coffee', 'cereal'), ('coffee', 'biscuit'), ('coffee', 'milk'), ('coffee', 'orange'), ('coffee', 'bread'), ('coffee', 'jam'), ('coffee', 'sugar'), ('coffee', 'tea'), ('bread', 'cereal'), ('bread', 'biscuit'), ('bread', 'milk'), ('bread', 'orange'), ('bread', 'coffee'), ('bread', 'jam'), ('bread', 'sugar'), ('bread', 'tea'), ('jam', 'cereal'), ('jam', 'biscuit'), ('jam', 'milk'), ('jam', 'orange'), ('jam', 'coffee'), ('jam', 'bread'), ('jam', 'sugar'), ('jam', 'tea'), ('sugar', 'cereal'), ('sugar', 'biscuit'), ('sugar', 'milk'), ('sugar', 'orange'), ('sugar', 'coffee'), ('sugar', 'bread'), ('sugar', 'jam'), ('sugar', 'tea'), ('tea', 'cereal'), ('tea', 'biscuit'), ('tea', 'milk'), ('tea', 'orange'), ('tea', 'coffee'), ('tea', 'bread'), ('tea', 'jam'), ('tea', 'sugar')]\n",
    "72\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae072fd1",
   "metadata": {},
   "source": [
    "## Support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c425604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "transactions\n",
    "\n",
    "\n",
    "[['milk', 'bread', 'biscuit'],\n",
    " ['bread', 'milk', 'biscuit', 'cereal'],\n",
    " ['bread', 'tea'],\n",
    " ['jam', 'bread', 'milk'],\n",
    " ['tea', 'biscuit'],\n",
    " ['bread', 'tea'],\n",
    " ['tea', 'cereal'],\n",
    " ['bread', 'tea', 'biscuit'],\n",
    " ['jam', 'bread', 'tea'],\n",
    " ['bread', 'milk'],\n",
    " ['coffee', 'orange', 'biscuit', 'cereal'],\n",
    " ['coffee', 'orange', 'biscuit', 'cereal'],\n",
    " ['coffee', 'sugar'],\n",
    " ['bread', 'coffee', 'orange'],\n",
    " ['bread', 'sugar', 'biscuit'],\n",
    " ['coffee', 'sugar', 'cereal'],\n",
    " ['bread', 'sugar', 'biscuit'],\n",
    " ['bread', 'coffee', 'sugar'],\n",
    " ['bread', 'coffee', 'sugar'],\n",
    " ['tea', 'milk', 'coffee', 'cereal']]\n",
    "\"\"\"\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the transaction encoder function from mlxtend\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Instantiate transaction encoder and identify unique items\n",
    "encoder = TransactionEncoder().fit(transactions)\n",
    "\n",
    "# One-hot encode transactions\n",
    "onehot = encoder.transform(transactions)\n",
    "\n",
    "# Convert one-hot encoded data to DataFrame\n",
    "onehot = pd.DataFrame(onehot, columns = encoder.columns_)\n",
    "\n",
    "# Print the one-hot encoded transaction dataset\n",
    "print(onehot)\n",
    "\"\"\"\n",
    "In [5]:\n",
    "onehot\n",
    "Out[5]:\n",
    "\n",
    "    biscuit  bread  cereal  coffee    jam   milk  orange  sugar    tea\n",
    "0      True   True   False   False  False   True   False  False  False\n",
    "1      True   True    True   False  False   True   False  False  False\n",
    "2     False   True   False   False  False  False   False  False   True\n",
    "3     False   True   False   False   True   True   False  False  False\n",
    "4      True  False   False   False  False  False   False  False   True\n",
    "5     False   True   False   False  False  False   False  False   True\n",
    "6     False  False    True   False  False  False   False  False   True\n",
    "7      True   True   False   False  False  False   False  False   True\n",
    "8     False   True   False   False   True  False   False  False   True\n",
    "9     False   True   False   False  False   True   False  False  False\n",
    "10     True  False    True    True  False  False    True  False  False\n",
    "11     True  False    True    True  False  False    True  False  False\n",
    "12    False  False   False    True  False  False   False   True  False\n",
    "13    False   True   False    True  False  False    True  False  False\n",
    "14     True   True   False   False  False  False   False   True  False\n",
    "15    False  False    True    True  False  False   False   True  False\n",
    "16     True   True   False   False  False  False   False   True  False\n",
    "17    False   True   False    True  False  False   False   True  False\n",
    "18    False   True   False    True  False  False   False   True  False\n",
    "19    False  False    True    True  False   True   False  False   True\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compute the support\n",
    "support = onehot.mean()\n",
    "\n",
    "# Print the support\n",
    "print(support)\n",
    "\"\"\"\n",
    "biscuit    0.40\n",
    "bread      0.65\n",
    "cereal     0.30\n",
    "coffee     0.40\n",
    "jam        0.10\n",
    "milk       0.25\n",
    "orange     0.15\n",
    "sugar      0.30\n",
    "tea        0.35\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dbb1f",
   "metadata": {},
   "source": [
    "## How  logical_and works in numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program explaining\n",
    "# logical_and() function\n",
    "import numpy as np\n",
    "  \n",
    "# input\n",
    "arr1 = [1, 3, False, 4]\n",
    "arr2 = [3, 0, True, False]\n",
    "  \n",
    "# output\n",
    "out_arr = np.logical_and(arr1, arr2)\n",
    "  \n",
    "print (\"Output Array : \", out_arr)\n",
    "\"\"\"\n",
    "Output Array :  [ True False False False]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a47ddd",
   "metadata": {},
   "source": [
    "## Business Question:- In this exercise, you'll make use of that DataFrame and the support metric to help the store's owner. First, she has asked you to identify frequently purchased items, which you'll do by computing support at the item-level. And second, she asked you to check whether the rule {jam} --- {bread} has a support of over 0.05. Note that onehot has been defined and is available. Additionally, pandas has been imported under the alias pd and numpy has been imported under the alias np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cdb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a jam+bread column to the DataFrame onehot\n",
    "onehot['jam+bread'] = np.logical_and(onehot['jam'], (onehot['bread']))\n",
    "\n",
    "# Compute the support\n",
    "support = onehot.mean()\n",
    "\n",
    "# Print the support values\n",
    "print(support)\n",
    "\"\"\"\n",
    "# Print the support values\n",
    "print(support)\n",
    "biscuit      0.40\n",
    "bread        0.65\n",
    "cereal       0.30\n",
    "coffee       0.40\n",
    "jam          0.10\n",
    "milk         0.25\n",
    "orange       0.15\n",
    "sugar        0.30\n",
    "tea          0.35\n",
    "jam+bread    0.10\n",
    "dtype: float64\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb95d46",
   "metadata": {},
   "source": [
    "# Recommending books with support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45663461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "books \n",
    "\n",
    "  Hunger  Potter  Twilight\n",
    "0      False    True     False\n",
    "1      False    True      True\n",
    "2      False   False     False\n",
    "3      False    True     False\n",
    "4      False   False     False\n",
    "...      ...     ...       ...\n",
    "8045   False   False     False\n",
    "8046   False   False     False\n",
    "8047   False   False      True\n",
    "8048    True   False      True\n",
    "8049   False   False     False\n",
    "\n",
    "[8050 rows x 3 columns]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Hunger and Potter\n",
    "supportHP = np.logical_and(books['Hunger'], books['Potter']).mean()\n",
    "\n",
    "# Compute support for Hunger and Twilight\n",
    "supportHT = np.logical_and(books['Hunger'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Print support values\n",
    "print(\"Hunger Games and Harry Potter: %.2f\" % supportHP)\n",
    "print(\"Hunger Games and Twilight: %.2f\" % supportHT)\n",
    "print(\"Harry Potter and Twilight: %.2f\" % supportPT)\n",
    "\n",
    "\"\"\"\n",
    "Hunger Games and Harry Potter: 0.12\n",
    "Hunger Games and Twilight: 0.09\n",
    "Harry Potter and Twilight: 0.14(Max)\n",
    "\n",
    "------------- Inference -------------------\n",
    "Based on the support metric, \n",
    "Harry Potter and Twilight appear to be the best options for cross-promotion. \n",
    "In the next problem, we'll consider whether we should use Harry Potter to promote Twilight or Twilight to promote Harry Potter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter\n",
    "supportP = books['Potter'].mean()\n",
    "\n",
    "# Compute support for Twilight\n",
    "supportT = books['Twilight'].mean()\n",
    "\n",
    "# Compute confidence for both rules\n",
    "confidencePT = supportPT / supportP\n",
    "confidenceTP = supportPT / supportT\n",
    "\n",
    "# Print results\n",
    "print('{0:.2f}, {1:.2f}'.format(confidencePT, confidenceTP))\n",
    "\n",
    "\"\"\"\n",
    "confidencePT:0.29\n",
    "confidenceTP:0.55\n",
    "\n",
    "----- Inference ---------\n",
    "Even though the support is identical for the two association rules, \n",
    "the confidence is much higher for Twilight -> Harry Potter, \n",
    "since Harry Potter has a higher support than Twilight.\n",
    "SO Use Twilight to promote Harry Potter,\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter\n",
    "supportP = books['Potter'].mean()\n",
    "\n",
    "# Compute support for Twilight\n",
    "supportT = books['Twilight'].mean()\n",
    "\n",
    "# Compute lift\n",
    "lift = supportPT / (supportP * supportT)\n",
    "\n",
    "# Print lift\n",
    "print(\"Lift: %.2f\" % lift)\n",
    "\n",
    "\"\"\"\n",
    "Lift: 1.15\n",
    "\n",
    "---- Inference------\n",
    "As it turns out, lift is greater than 1.0.Twilight to promote Harry Potter, \n",
    "This could give us some confidence that the association rule we recommended did not arise by random chance.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bd6b5",
   "metadata": {},
   "source": [
    "## Conviction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df88c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conviction(antecedent, consequent):\n",
    "\t# Compute support for antecedent AND consequent\n",
    "\tsupportAC = np.logical_and(antecedent, consequent).mean()\n",
    "\n",
    "\t# Compute support for antecedent\n",
    "\tsupportA = antecedent.mean()\n",
    "\n",
    "\t# Compute support for NOT consequent\n",
    "\tsupportnC = 1.0 - consequent.mean()\n",
    "\n",
    "\t# Compute support for antecedent and NOT consequent\n",
    "\tsupportAnC = supportA - supportAC\n",
    "\n",
    "    # Return conviction\n",
    "\treturn supportA * supportnC / supportAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51255eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute conviction for twilight -> potter and potter -> twilight\n",
    "convictionTP = conviction(twilight, potter)\n",
    "convictionPT = conviction(potter, twilight)\n",
    "\n",
    "# Compute conviction for twilight -> hunger and hunger -> twilight\n",
    "convictionTH = conviction(twilight, hunger)\n",
    "convictionHT = conviction(hunger, twilight)\n",
    "\n",
    "# Compute conviction for potter -> hunger and hunger -> potter\n",
    "convictionPH = conviction(potter, hunger)\n",
    "convictionHP = conviction(hunger, potter)\n",
    "\n",
    "# Print results\n",
    "print('Harry Potter -> Twilight: ', convictionPT)\n",
    "print('Twilight -> Potter: ', convictionTP)\n",
    "'''\n",
    "Harry Potter -> Twilight:  1.0534570072738598\n",
    "Twilight -> Potter:  1.1550539077290998 \n",
    "Inference : Twilight to promote Harry Potter\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e7a64",
   "metadata": {},
   "source": [
    "# Zangs-Metric : is between -1 to 1 , -1 mean strong disassociation and 1 is strong association "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the support of Twilight and Harry Potter\n",
    "supportT = books['Twilight'].mean()\n",
    "supportP = books['Potter'].mean()\n",
    "\n",
    "# Compute the support of both books\n",
    "supportTP = np.logical_and(books['Twilight'], books['Potter']).mean()\n",
    "\n",
    "# Complete the expressions for the numerator and denominator\n",
    "numerator = supportTP - supportT*supportP\n",
    "denominator = max(supportTP*(1-supportT), supportT*(supportP-supportTP))\n",
    "\n",
    "# Compute and print Zhang's metric\n",
    "zhang = numerator / denominator\n",
    "print(zhang)\n",
    "'''\n",
    "0.17231567178855997\n",
    "`if Twilight then Harry Potter'' proved robust. \n",
    "It had a positive value for Zhang's metric, indicating that the two books are not dissociated.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute Zhang's metric\n",
    "def zhang(antecedent, consequent):\n",
    "\t# Compute the support of each book\n",
    "\tsupportA = antecedent.mean()\n",
    "\tsupportC = consequent.mean()\n",
    "\n",
    "\t# Compute the support of both books\n",
    "\tsupportAC = np.logical_and(antecedent, consequent).mean()\n",
    "\n",
    "\t# Complete the expressions for the numerator and denominator\n",
    "\tnumerator = supportAC - supportA*supportC\n",
    "\tdenominator = max(supportAC*(1-supportA), supportA*(supportC-supportAC))\n",
    "\n",
    "\t# Return Zhang's metric\n",
    "\treturn numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cb30f",
   "metadata": {},
   "source": [
    "## The founder of the ebook start-up has returned for additional consulting services. She has sent you a list of itemsets she's investigating and has asked you to determine whether any of them contain items that are dissociated. When you're finished, she has asked that you add the metric you use to a column in the rules DataFrame, which is available to you, and currently contains columns for antecedents and consequents.\n",
    "\n",
    "The itemsets are available as a list of lists called itemsets. Each list contains the antecedent first and the consequent second. You also have access to the books DataFrame from previous exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "books \n",
    "\n",
    "\n",
    "      Hunger  Potter  Twilight  Mockingbird  Gatsby\n",
    "0      False    True     False         True    True\n",
    "1      False    True      True        False    True\n",
    "2      False   False     False         True   False\n",
    "3      False    True     False        False    True\n",
    "4      False   False     False        False    True\n",
    "...      ...     ...       ...          ...     ...\n",
    "8045   False   False     False         True    True\n",
    "8046   False   False     False         True   False\n",
    "8047   False   False      True        False   False\n",
    "8048    True   False      True        False   False\n",
    "8049   False   False     False         True   False\n",
    "\n",
    "----------------------------------------------\n",
    "In [5]:\n",
    "itemsets\n",
    "Out[5]:\n",
    "\n",
    "[['Potter', 'Hunger'],\n",
    " ['Twilight', 'Hunger'],\n",
    " ['Mockingbird', 'Hunger'],\n",
    " ['Gatsby', 'Hunger'],\n",
    " ['Potter', 'Twilight'],\n",
    " ['Potter', 'Mockingbird'],\n",
    " ['Potter', 'Gatsby'],\n",
    " ['Mockingbird', 'Twilight'],\n",
    " ['Gatsby', 'Twilight'],\n",
    " ['Mockingbird', 'Gatsby']]\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b810fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list for Zhang's metric\n",
    "zhangs_metric = []\n",
    "\n",
    "# Loop over lists in itemsets\n",
    "for itemset in itemsets:\n",
    "    # Extract the antecedent and consequent columns\n",
    "\tantecedent = books[itemset[0]]\n",
    "\tconsequent = books[itemset[1]]\n",
    "    #print('antecedent',antecedent)\n",
    "\t#print('consequent',consequent)\n",
    "    # Complete Zhang's metric and append it to the list\n",
    "\tzhangs_metric.append(zhang(antecedent, consequent))\n",
    "    \n",
    "# Print results\n",
    "rules['zhang'] = zhangs_metric\n",
    "print(rules)\n",
    "\"\"\"\n",
    "\n",
    " antecedents  consequents     zhang\n",
    "    0       Potter       Hunger -0.306049\n",
    "    1     Twilight       Hunger  0.109357\n",
    "    2  Mockingbird       Hunger -0.525436\n",
    "    3       Gatsby       Hunger -0.550446\n",
    "    4       Potter     Twilight  0.245118\n",
    "    5       Potter  Mockingbird -0.065537\n",
    "    6       Potter       Gatsby -0.165572\n",
    "    7  Mockingbird     Twilight -0.319008\n",
    "    8       Gatsby     Twilight -0.370875\n",
    "    9  Mockingbird       Gatsby  0.466460\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8709d7",
   "metadata": {},
   "source": [
    "## Multi-Metric Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0144551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In [1]:\n",
    "rules\n",
    "Out[1]:\n",
    "\n",
    "          antecedents                      consequents  antecedent support  consequent support   support  confidence      lift  leverage  conviction\n",
    "0            (Hunger)                         (Potter)            0.319130            0.477516  0.123851    0.388089  0.812725 -0.028539    0.853857\n",
    "1            (Potter)                         (Hunger)            0.477516            0.319130  0.123851    0.259365  0.812725 -0.028539    0.919305\n",
    "2            (Hunger)                       (Twilight)            0.319130            0.256770  0.089193    0.279486  1.088468  0.007249    1.031527\n",
    "3          (Twilight)                         (Hunger)            0.256770            0.319130  0.089193    0.347363  1.088468  0.007249    1.043260\n",
    "4            (Hunger)                    (Mockingbird)            0.319130            0.476522  0.096273    0.301674  0.633075 -0.055799    0.749619\n",
    "..                ...                              ...                 ...                 ...       ...         ...       ...       ...         ...\n",
    "145  (Potter, Gatsby)          (Twilight, Mockingbird)            0.127702            0.098261  0.024348    0.190661  1.940360  0.011800    1.114168\n",
    "146        (Twilight)    (Potter, Mockingbird, Gatsby)            0.256770            0.089814  0.024348    0.094823  1.055779  0.001286    1.005535\n",
    "147     (Mockingbird)       (Twilight, Potter, Gatsby)            0.476522            0.034161  0.024348    0.051095  1.495687  0.008069    1.017845\n",
    "148          (Potter)  (Twilight, Mockingbird, Gatsby)            0.477516            0.036273  0.024348    0.050989  1.405678  0.007027    1.015506\n",
    "149          (Gatsby)  (Twilight, Potter, Mockingbird)            0.295155            0.062981  0.024348    0.082492  1.309778  0.005759    1.021264\n",
    "\n",
    "[150 rows x 9 columns]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the rules DataFrame using the .head() method\n",
    "print(rules.head())\n",
    "\n",
    "# Select the subset of rules with antecedent support greater than 0.05\n",
    "rules = rules[rules['antecedent support'] > 0.05]\n",
    "\n",
    "# Select the subset of rules with a consequent support greater than 0.02\n",
    "rules = rules[rules['consequent support'] > 0.02]\n",
    "\n",
    "# Select the subset of rules with a conviction greater than 1.01\n",
    "rules = rules[rules['conviction'] > 1.01]\n",
    "\n",
    "# Print remaining rules\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ea210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " antecedents    consequents  antecedent support  consequent support   support  confidence      lift  leverage  conviction\n",
    "0    (Hunger)       (Potter)            0.319130            0.477516  0.123851    0.388089  0.812725 -0.028539    0.853857\n",
    "1    (Potter)       (Hunger)            0.477516            0.319130  0.123851    0.259365  0.812725 -0.028539    0.919305\n",
    "2    (Hunger)     (Twilight)            0.319130            0.256770  0.089193    0.279486  1.088468  0.007249    1.031527\n",
    "3  (Twilight)       (Hunger)            0.256770            0.319130  0.089193    0.347363  1.088468  0.007249    1.043260\n",
    "4    (Hunger)  (Mockingbird)            0.319130            0.476522  0.096273    0.301674  0.633075 -0.055799    0.749619\n",
    "               antecedents                      consequents  antecedent support  consequent support   support  confidence      lift  leverage  conviction\n",
    "2                 (Hunger)                       (Twilight)            0.319130            0.256770  0.089193    0.279486  1.088468  0.007249    1.031527\n",
    "3               (Twilight)                         (Hunger)            0.256770            0.319130  0.089193    0.347363  1.088468  0.007249    1.043260\n",
    "8               (Twilight)                         (Potter)            0.256770            0.477516  0.140621    0.547654  1.146881  0.018009    1.155054\n",
    "9                 (Potter)                       (Twilight)            0.477516            0.256770  0.140621    0.294485  1.146881  0.018009    1.053457\n",
    "18           (Mockingbird)                         (Gatsby)            0.476522            0.295155  0.186087    0.390511  1.323070  0.045439    1.156452\n",
    "..                     ...                              ...                 ...                 ...       ...         ...       ...       ...         ...\n",
    "143  (Potter, Mockingbird)               (Twilight, Gatsby)            0.219503            0.053540  0.024348    0.110922  2.071754  0.012596    1.064541\n",
    "145       (Potter, Gatsby)          (Twilight, Mockingbird)            0.127702            0.098261  0.024348    0.190661  1.940360  0.011800    1.114168\n",
    "147          (Mockingbird)       (Twilight, Potter, Gatsby)            0.476522            0.034161  0.024348    0.051095  1.495687  0.008069    1.017845\n",
    "148               (Potter)  (Twilight, Mockingbird, Gatsby)            0.477516            0.036273  0.024348    0.050989  1.405678  0.007027    1.015506\n",
    "149               (Gatsby)  (Twilight, Potter, Mockingbird)            0.295155            0.062981  0.024348    0.082492  1.309778  0.005759    1.021264\n",
    "\n",
    "[82 rows x 9 columns]\n",
    "\n",
    "\n",
    "\n",
    "------ Inference:\n",
    "ou have now successfully performed multi-metric filtering. \n",
    "In the final exercise in this chapter, you'll go even further by including an advanced metric.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the lift threshold to 1.5\n",
    "rules = rules[rules['lift'] > 1.5]\n",
    "\n",
    "# Set the conviction threshold to 1.0\n",
    "rules = rules[rules['conviction']>1]\n",
    "\n",
    "# Set the threshold for Zhang's rule to 0.65\n",
    "rules = rules[rules['zhang']>0.65]\n",
    "\n",
    "# Print rule\n",
    "print(rules[['antecedents','consequents']])\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "<script.py> output:\n",
    "                     antecedents               consequents\n",
    "    115    (Potter, Mockingbird)          (Hunger, Gatsby)\n",
    "    119            (Mockingbird)  (Hunger, Potter, Gatsby)\n",
    "    127    (Hunger, Mockingbird)        (Twilight, Gatsby)\n",
    "    129  (Twilight, Mockingbird)          (Hunger, Gatsby)\n",
    "    143    (Potter, Mockingbird)        (Twilight, Gatsby)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf284b",
   "metadata": {},
   "source": [
    "## Performing aggregation\n",
    "After completing minor consulting jobs for a library and an ebook seller, you've finally received your first big market basket analysis project: advising an online novelty gifts retailer on cross-promotions. Since the retailer has never previously hired a data scientist, it would like you to start the project by exploring its transaction data. It has asked you to perform aggregation for all signs in the dataset and also compute the support for this category. Note that pandas has been imported for you as pd. Additionally, the data has been imported in one-hot encoded format as onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeee1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "onehot\n",
    "\n",
    "      50'S CHRISTMAS GIFT BAG LARGE   DOLLY GIRL BEAKER   I LOVE LONDON MINI BACKPACK   RED SPOT GIFT BAG LARGE   SPACEBOY BABY GIFT SET  12 MESSAGE CARDS WITH ENVELOPES  12 PENCIL SMALL TUBE WOODLAND  ...  ZINC FOLKART SLEIGH BELLS  ZINC METAL HEART DECORATION  ZINC T-LIGHT HOLDER STAR LARGE  ZINC T-LIGHT HOLDER STARS SMALL  ZINC WILLIE WINKIE  CANDLE STICK  amazon adjust  check\n",
    "0                              False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "1                              False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "2                              False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "3                              False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "4                              False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "...                              ...                 ...                           ...                       ...                      ...                              ...                            ...  ...                        ...                          ...                             ...                              ...                               ...            ...    ...\n",
    "1325                           False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "1326                           False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "1327                           False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "1328                           False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "1329                           False               False                         False                     False                    False                            False                          False  ...                      False                        False                           False                            False                             False          False  False\n",
    "\n",
    "[1330 rows x 1039 columns]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column headers for sign items\n",
    "sign_headers = [i for i in onehot.columns if i.lower().find('sign')>=0]\n",
    "\"\"\"\n",
    "In [6]:\n",
    "sign_headers\n",
    "Out[6]:\n",
    "\n",
    "['60 CAKE CASES DOLLY GIRL DESIGN',\n",
    " 'AREA PATROLLED METAL SIGN',\n",
    " 'BAKING SET SPACEBOY DESIGN',\n",
    " 'BATHROOM METAL SIGN',\n",
    " 'BEWARE OF THE CAT METAL SIGN ',\n",
    " 'BIRDS MOBILE VINTAGE DESIGN',\n",
    " 'CERAMIC BOWL WITH LOVE HEART DESIGN',\n",
    " 'CERAMIC CAKE DESIGN SPOTTED MUG',\n",
    " 'CHARLOTTE BAG APPLES DESIGN',\n",
    " 'CHARLOTTE BAG SUKI DESIGN',\n",
    " 'CHILDRENS APRON APPLES DESIGN',\n",
    " 'CHILDRENS APRON SPACEBOY DESIGN',\n",
    " 'COFFEE MUG PEARS  DESIGN',\n",
    " 'COOK WITH WINE METAL SIGN ',\n",
    " 'COTTON APRON PANTRY DESIGN',\n",
    " 'FAIRY CAKE DESIGN UMBRELLA',\n",
    " 'FRENCH BLUE METAL DOOR SIGN 3',\n",
    " 'FRENCH BLUE METAL DOOR SIGN 5',\n",
    " 'FRENCH BLUE METAL DOOR SIGN 6',\n",
    " 'FRENCH BLUE METAL DOOR SIGN 9',\n",
    " 'FRENCH BLUE METAL DOOR SIGN No',\n",
    " 'FRENCH TOILET SIGN BLUE METAL',\n",
    " 'FRENCH WC SIGN BLUE METAL',\n",
    " 'GIN + TONIC DIET METAL SIGN',\n",
    " 'HAND OVER THE CHOCOLATE   SIGN ',\n",
    " 'HAND WARMER BABUSHKA DESIGN',\n",
    " 'HAND WARMER BIRD DESIGN',\n",
    " 'HAND WARMER OWL DESIGN',\n",
    " 'HAND WARMER SCOTTY DOG DESIGN',\n",
    " 'HOME SWEET HOME METAL SIGN ',\n",
    " 'JUMBO BAG DOLLY GIRL DESIGN',\n",
    " 'JUMBO BAG SPACEBOY DESIGN',\n",
    " 'KITTENS DESIGN FLANNEL',\n",
    " 'LADIES & GENTLEMEN METAL SIGN',\n",
    " 'LAUNDRY 15C METAL SIGN',\n",
    " 'LUNCH BAG ALPHABET DESIGN',\n",
    " 'LUNCH BAG APPLE DESIGN',\n",
    " 'LUNCH BAG SPACEBOY DESIGN ',\n",
    " 'LUNCH BAG SUKI DESIGN ',\n",
    " 'LUNCH BAG VINTAGE LEAF DESIGN',\n",
    " 'MEMO BOARD COTTAGE DESIGN',\n",
    " 'METAL SIGN DROP YOUR PANTS',\n",
    " 'METAL SIGN EMPIRE TEA',\n",
    " 'METAL SIGN HIS DINNER IS SERVED',\n",
    " 'MONEY BOX KINGS CHOICE DESIGN',\n",
    " 'MONEY BOX POCKET MONEY DESIGN',\n",
    " 'N0 SINGING METAL SIGN',\n",
    " 'NO JUNK MAIL METAL SIGN',\n",
    " 'PARTY METAL SIGN ',\n",
    " 'PEG BAG APPLES DESIGN',\n",
    " 'PLEASE ONE PERSON METAL SIGN',\n",
    " 'POTTERING IN THE SHED METAL SIGN',\n",
    " 'RECIPE BOX PANTRY YELLOW DESIGN',\n",
    " 'RED CHARLIE+LOLA PERSONAL DOORSIGN',\n",
    " 'RIBBON REEL HEARTS DESIGN ',\n",
    " 'RIBBON REEL LACE DESIGN ',\n",
    " 'SET 20 NAPKINS FAIRY CAKES DESIGN ',\n",
    " 'SET OF 3 CAKE TINS PANTRY DESIGN ',\n",
    " 'SET OF 36 DOILIES PANTRY DESIGN',\n",
    " 'SET OF 36 DOILIES SPACEBOY DESIGN ',\n",
    " 'SET OF 6 SPICE TINS PANTRY DESIGN',\n",
    " 'SET OF 60 PANTRY DESIGN CAKE CASES ',\n",
    " 'SMALL DOLLY MIX DESIGN ORANGE BOWL',\n",
    " 'STRIPES DESIGN TEDDY',\n",
    " 'TOILET SIGN OCCUPIED OR VACANT',\n",
    " 'WASHROOM METAL SIGN',\n",
    " 'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    " 'WRAP ALPHABET DESIGN',\n",
    " 'WRAP POPPIES  DESIGN',\n",
    " \"YOU'RE CONFUSING ME METAL SIGN \"]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Select columns of sign items using sign_headers\n",
    "sign_columns = onehot[sign_headers]\n",
    "\n",
    "\n",
    "# Perform aggregation of sign items into sign category\n",
    "signs = sign_columns.sum(axis = 1) >= 1.0\n",
    "\n",
    "# Print support for signs\n",
    "print('Share of Signs: %.2f' % signs.mean())\n",
    "\n",
    "\"\"\"\n",
    "If you look at the printed statement, you'll notice that support for signs is 0.10, \n",
    "which suggests that signs are an important category of items for the retailer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847dc85",
   "metadata": {},
   "source": [
    "## Defining an aggregation function\n",
    "Surprised by the high share of sign items in its inventory, the retailer decides that it makes sense to do further aggregation for different categories to explore the data better. This seems trivial to you, but the retailer has not previously been able to perform even a basic descriptive analysis of its transaction and items.\n",
    "\n",
    "The retailer asks you to perform aggregation for the candles, bags, and boxes categories. To simplify the task, you decide to write a function. It will take a string that contains an item's category. It will then output a DataFrame that indicates whether each transaction includes items from that category. Note that pandas has been imported for you as pd. Additionally, the data has been imported in one-hot encoded format as onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(item):\n",
    "\t# Select the column headers for sign items in onehot\n",
    "\titem_headers = [i for i in onehot.columns if i.lower().find(item)>=0]\n",
    "\n",
    "\t# Select columns of sign items\n",
    "\titem_columns = onehot[item_headers]\n",
    "\n",
    "\t# Return category of aggregated items\n",
    "\treturn item_columns.sum(axis = 1) >= 1.0\n",
    "\n",
    "# Aggregate items for the bags, boxes, and candles categories  \n",
    "bags = aggregate('bag')\n",
    "boxes = aggregate('box')\n",
    "candles = aggregate('candle')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "In [1]:\n",
    "bags \n",
    "Out[1]:\n",
    "\n",
    "0       False\n",
    "1        True\n",
    "2       False\n",
    "3       False\n",
    "4        True\n",
    "        ...  \n",
    "1325    False\n",
    "1326    False\n",
    "1327    False\n",
    "1328     True\n",
    "1329    False\n",
    "Length: 1330, dtype: bool\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce41a0",
   "metadata": {},
   "source": [
    "## Pruning and Apriori\n",
    "In the video, we introduced the Apriori algorithm, which made use of the Apriori principle to prune itemsets. The Apriori principle tells us that subsets of frequent itemsets are frequent. Thus, if we find an infrequent itemset, which we'll call {X}, then it must be the case that {X, Y} is also infrequent, so we may eliminate it without computing its support.\n",
    "\n",
    "In this exercise, you'll be given itemsets and information about the frequency of its subsets. You will need to decide whether the information is sufficient to prune the itemset or whether we need to compute its support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import apriori from mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Compute frequent itemsets using the Apriori algorithm\n",
    "frequent_itemsets = apriori(onehot, \n",
    "                            min_support = 0.006, \n",
    "                            max_len = 3, \n",
    "                            use_colnames = True)\n",
    "\n",
    "# Print a preview of the frequent itemsets\n",
    "print(frequent_itemsets.head())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "<script.py> output:\n",
    "        support                              itemsets\n",
    "    0  0.006767          (HOT WATER BOTTLE KEEP CALM)\n",
    "    1  0.007519             (JUMBO BAG RED RETROSPOT)\n",
    "    2  0.006015     (PAPER CHAIN KIT 50'S CHRISTMAS )\n",
    "    3  0.006015                      (POPCORN HOLDER)\n",
    "    4  0.006767  (WHITE HANGING HEART T-LIGHT HOLDER)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46543546",
   "metadata": {},
   "source": [
    "## Selecting a support threshold\n",
    "The manager of the online gift store looks at the results you provided from the previous exercise and commends you for the good work. She does, however, raise an issue: all of the itemsets you identified contain only one item. She asks whether it would be possible to use a less restrictive rule and to generate more itemsets, possibly including those with multiple items.\n",
    "\n",
    "After agreeing to do this, you think about what might explain the lack of itemsets with more than 1 item. It can't be the max_len parameter, since that was set to three. You decide it must be support and decide to test two different values, each time checking how many additional itemsets are generated. Note that pandas is available as pd and the one-hot encoded data is available as onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import apriori from mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "\n",
    "# Compute frequent itemsets using a support of 0.003 and length of 3\n",
    "frequent_itemsets_1 = apriori(onehot, min_support = 0.003, \n",
    "                            max_len = 3, use_colnames = True)\n",
    "\n",
    "# Compute frequent itemsets using a support of 0.001 and length of 3\n",
    "frequent_itemsets_2 = apriori(onehot, min_support = 0.001, \n",
    "                            max_len = 3, use_colnames = True)\n",
    "\n",
    "# Print the number of freqeuent itemsets\n",
    "print(len(frequent_itemsets_1), len(frequent_itemsets_2))\n",
    "\n",
    "\"\"\"\n",
    "91 429\n",
    ">>\n",
    "generated by the Apriori algorithm using a support value of 0.002\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99d127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f959ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde89d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc922edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
